import streamlit as st
import openai
import google.generativeai as genai
import anthropic
import PyPDF2
import docx
import json
import hashlib
import os
from datetime import datetime, timedelta

# ============================================
# íŽ˜ì´ì§€ ì„¤ì •
# ============================================
st.set_page_config(
    page_title="ðŸŽ¯ Strategist AI Pro",
    layout="wide",
    page_icon="ðŸŽ¯",
    initial_sidebar_state="expanded"
)

# ============================================
# ë‹¤êµ­ì–´ ì§€ì› ì‹œìŠ¤í…œ
# ============================================
LANGUAGES = {
    "ko": {
        "name": "í•œêµ­ì–´", "flag": "ðŸ‡°ðŸ‡·",
        "app_title": "ðŸŽ¯ Strategist AI Pro",
        "app_subtitle": "í•™ìˆ  ì—°êµ¬ ì „ëžµ ì»¨ì„¤íŒ… | 3-Engine í•˜ì´ë¸Œë¦¬ë“œ | APA ìžë™ìƒì„±",
        "login": "ë¡œê·¸ì¸", "signup": "íšŒì›ê°€ìž…", "logout": "ë¡œê·¸ì•„ì›ƒ",
        "username": "ì•„ì´ë””", "password": "ë¹„ë°€ë²ˆí˜¸", "email": "ì´ë©”ì¼",
        "password_confirm": "ë¹„ë°€ë²ˆí˜¸ í™•ì¸", "login_button": "ë¡œê·¸ì¸", "signup_button": "íšŒì›ê°€ìž…",
        "test_account": "ðŸ§ª í…ŒìŠ¤íŠ¸ ê³„ì • ë³´ê¸°", "free_plan": "ðŸ†“ FREE í”Œëžœ", "pro_plan": "ðŸ’Ž PRO íšŒì›",
        "remaining": "ë‚¨ì€ íšŸìˆ˜", "unlimited": "ë¬´ì œí•œ", "upgrade": "ðŸ’Ž PRO ì—…ê·¸ë ˆì´ë“œ",
        # íƒ­ ì´ë¦„
        "contemplate_tab": "ðŸ§  ì‚¬ìœ ì˜ ë°©", "master_tab": "ðŸŽ“ ê±°ìž¥ê³¼ì˜ ëŒ€í™”",
        "gap_tab": "ðŸŒ± Gap-Mining", "method_tab": "âš–ï¸ ë°©ë²•ë¡ ", "draft_tab": "ðŸ“ ë“œëž˜í”„íŠ¸",
        "polish_tab": "âœï¸ ìœ¤ë¬¸", "diagnosis_tab": "ðŸ”¬ ìµœì¢… ì§„ë‹¨", "submit_tab": "ðŸ íˆ¬ê³ ",
        "references_tab": "ðŸ“š ì°¸ê³ ë¬¸í—Œ", "storage_tab": "ðŸ’¾ ì €ìž¥ì†Œ",
        # ì‚¬ìœ ì˜ ë°©
        "contemplate_title": "ðŸ§  ì‚¬ìœ ì˜ ë°©",
        "contemplate_desc": "ðŸ’­ ë¹„ì •í˜•ì  ê³µìƒ â†’ ì‹¤ì¦ì  ì—°êµ¬ ì„¤ê³„ ì „í™˜ | Gemini Bridge Logic",
        "contemplate_input": "ìžìœ ë¡­ê²Œ ë– ì˜¤ë¥´ëŠ” ìƒê°, ì‚¬íšŒ ì´ìŠˆ, ê³µìƒì„ ìž…ë ¥í•˜ì„¸ìš”",
        "contemplate_placeholder": "ì˜ˆ: ìš”ì¦˜ ì¹´íŽ˜ì—ì„œ ë…¸íŠ¸ë¶ í•˜ëŠ” ì‚¬ëžŒì´ ë§Žì•„ì¡ŒëŠ”ë°, ì´ê²Œ ìƒì‚°ì„±ì— ì˜í–¥ì„ ì¤„ê¹Œ?\nì˜ˆ: SNSì—ì„œ ë³¸ ë‰´ìŠ¤ë§Œ ë³´ëŠ” ì‚¬ëžŒë“¤ì´ ì ì  ê·¹ë‹¨ì ì´ ë˜ëŠ” ê²ƒ ê°™ë‹¤\nì˜ˆ: AIê°€ ê·¸ë¦¼ì„ ê·¸ë¦¬ë©´ ê·¸ê±´ ì˜ˆìˆ ì¼ê¹Œ?",
        "contemplate_button": "ðŸ§  ì—°êµ¬ ì„¤ê³„ë¡œ ì „í™˜",
        "contemplate_depth": "ì‚¬ìœ  ê¹Šì´",
        "depth_spark": "ðŸ”¥ ìŠ¤íŒŒí¬ (ë¹ ë¥¸ ë³€í™˜)",
        "depth_explore": "ðŸ”­ íƒìƒ‰ (ë³€ìˆ˜ í™•ìž¥)",
        "depth_architect": "ðŸ—ï¸ ì„¤ê³„ (ì™„ì „ í”„ë ˆìž„ì›Œí¬)",
        # ê±°ìž¥ê³¼ì˜ ëŒ€í™”
        "master_title": "ðŸŽ“ ê±°ìž¥ê³¼ì˜ ëŒ€í™”",
        "master_desc": "ðŸ“– ê±°ìž¥ì˜ ì¸ì‹ë¡ ìœ¼ë¡œ ë‹¹ì‹ ì˜ ì—°êµ¬ ë¬¸ì œë¥¼ ìž¬í•´ì„ | Perplexity ì‹¤ì‹œê°„ ê²€ì¦",
        "master_input": "ê±°ìž¥ì—ê²Œ ì§ˆë¬¸í•  ì—°êµ¬ ë¬¸ì œë¥¼ ìž…ë ¥í•˜ì„¸ìš”",
        "master_placeholder": "ì˜ˆ: ë””ì§€í„¸ í”Œëž«í¼ì´ ë…¸ë™ì‹œìž¥ ë¶ˆí‰ë“±ì„ ì‹¬í™”ì‹œí‚¤ëŠ”ê°€?\nì˜ˆ: ì–‘ìžì»´í“¨íŒ…ì´ ì•”í˜¸ì²´ê³„ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€?\nì˜ˆ: ìƒì„±AI ì‹œëŒ€ì˜ ì €ìž‘ê¶Œì€ ì–´ë–»ê²Œ ìž¬ì •ì˜ë˜ì–´ì•¼ í•˜ëŠ”ê°€?",
        "master_button": "ðŸŽ“ ê±°ìž¥ì—ê²Œ ì§ˆë¬¸",
        "master_select": "ê±°ìž¥ ì„ íƒ",
        "master_category": "ë¶„ì•¼",
        "cat_social": "ðŸ›ï¸ ì‚¬íšŒê³¼í•™",
        "cat_engineer": "âš™ï¸ ê³µí•™Â·ìžì—°ê³¼í•™",
        "cat_art": "ðŸŽ¨ ì˜ˆìˆ Â·ì¸ë¬¸í•™",
        # ê¸°ì¡´ ê¸°ëŠ¥
        "gap_title": "ðŸŒ± Gap-Mining", "gap_desc": "ì—°êµ¬ ë…ì°½ì„± ê²€ì¦ + ê³µë°± ë°œê²¬ + ì—°êµ¬ì§ˆë¬¸ ê°œì„ ",
        "method_title": "âš–ï¸ ë°©ë²•ë¡  ê²€ì¦", "method_desc": "ì‹¬ì‚¬ìœ„ì› ê³µê²© ì˜ˆìƒ + ë°©ì–´ ì „ëžµ",
        "draft_title": "ðŸ“ ë“œëž˜í”„íŠ¸ ìž‘ì„± (PRO)", "draft_desc": "Claude AI í•™ìˆ ì  ì´ˆì•ˆ ìž‘ì„±",
        "polish_title": "âœï¸ ìœ¤ë¬¸/êµì • (PRO)", "polish_desc": "Claude AI í•™ìˆ ì  í‘œí˜„ ìœ¤ë¬¸",
        "diagnosis_title": "ðŸ”¬ ìµœì¢… ë…¼ë¬¸ ì§„ë‹¨ (PRO)", "diagnosis_desc": "3-Engine í•˜ì´ë¸Œë¦¬ë“œ: Perplexity + Gemini + Claude",
        "submit_title": "ðŸ íˆ¬ê³  ì „ëžµ", "submit_desc": "ì €ë„ ì¶”ì²œ + Abstract ê°œì„ ",
        "references_title": "ðŸ“š APA ì°¸ê³ ë¬¸í—Œ", "references_desc": "Perplexity ê¸°ë°˜ ìµœì‹  ë…¼ë¬¸ + APA 7íŒ",
        # ê³µí†µ
        "file_upload": "ðŸ“„ íŒŒì¼ ì—…ë¡œë“œ", "analyze_button": "ðŸ” ë¶„ì„ ì‹œìž‘", "validate_button": "ðŸ§ª ê²€ì¦",
        "strategy_button": "ðŸ“¤ ì „ëžµ ìƒì„±", "search_button": "ðŸ“š ì°¸ê³ ë¬¸í—Œ ì°¾ê¸°", "analyzing": "ë¶„ì„ ì¤‘...",
        "result": "ê²°ê³¼", "download": "ðŸ’¾ ì €ìž¥", "ask_more": "ðŸ’¬ ì—°ì† ì§ˆë¬¸", "repolish": "ðŸ”„ ë‹¤ì‹œ ìœ¤ë¬¸",
        "placeholder_idea": "ì—°êµ¬ ì•„ì´ë””ì–´ë¥¼ ìž…ë ¥í•˜ì„¸ìš”...", "placeholder_method": "ë°©ë²•ë¡ ì„ ìž…ë ¥í•˜ì„¸ìš”...",
        "placeholder_abstract": "ì´ˆë¡ì„ ìž…ë ¥í•˜ì„¸ìš”...", "placeholder_topic": "ì—°êµ¬ ì£¼ì œë¥¼ ìž…ë ¥í•˜ì„¸ìš”...",
        "error_empty": "âŒ ë‚´ìš©ì„ ìž…ë ¥í•´ì£¼ì„¸ìš”.", "error_limit": "âŒ ë¬´ë£Œ ì‚¬ìš© íšŸìˆ˜ë¥¼ ëª¨ë‘ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤!",
        "welcome": "í™˜ì˜í•©ë‹ˆë‹¤", "account_info": "ê³„ì • ì •ë³´", "weekly_reset": "*ë§¤ì£¼ ì›”ìš”ì¼ 0ì‹œ ë¦¬ì…‹*",
        "security": "ðŸ”’ ë³´ì•ˆ: SHA256 ì•”í˜¸í™”", "invalid_cred": "âŒ ì•„ì´ë”” ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤",
        "pro_only": "ðŸ’Ž PRO ì „ìš© ê¸°ëŠ¥ìž…ë‹ˆë‹¤!", "draft_topic": "ì—°êµ¬ ì£¼ì œ ë° ê°œìš”",
        "section_select": "ìž‘ì„±í•  ì„¹ì…˜", "polish_input": "ìœ¤ë¬¸í•  í…ìŠ¤íŠ¸", "full_paper": "ì™„ì„±ëœ ë…¼ë¬¸",
        "generate_draft": "ðŸ“ ë“œëž˜í”„íŠ¸ ìƒì„±", "start_polish": "âœï¸ ìœ¤ë¬¸ ì‹œìž‘", "diagnose_button": "ðŸ”¬ ì§„ë‹¨ ì‹œìž‘"
    },
    "en": {
        "name": "English", "flag": "ðŸ‡ºðŸ‡¸",
        "app_title": "ðŸŽ¯ Strategist AI Pro",
        "app_subtitle": "Academic Research Strategy | 3-Engine Hybrid | APA Generator",
        "login": "Login", "signup": "Sign Up", "logout": "Logout",
        "username": "Username", "password": "Password", "email": "Email",
        "password_confirm": "Confirm Password", "login_button": "Login", "signup_button": "Sign Up",
        "test_account": "ðŸ§ª View Test Account", "free_plan": "ðŸ†“ FREE Plan", "pro_plan": "ðŸ’Ž PRO Member",
        "remaining": "Remaining", "unlimited": "Unlimited", "upgrade": "ðŸ’Ž Upgrade to PRO",
        "contemplate_tab": "ðŸ§  Contemplation", "master_tab": "ðŸŽ“ Master Dialogue",
        "gap_tab": "ðŸŒ± Gap-Mining", "method_tab": "âš–ï¸ Methodology", "draft_tab": "ðŸ“ Draft",
        "polish_tab": "âœï¸ Polish", "diagnosis_tab": "ðŸ”¬ Diagnosis", "submit_tab": "ðŸ Submission",
        "references_tab": "ðŸ“š References", "storage_tab": "ðŸ’¾ Storage",
        "contemplate_title": "ðŸ§  Contemplation Room",
        "contemplate_desc": "ðŸ’­ Raw ideas â†’ Empirical research design | Gemini Bridge Logic",
        "contemplate_input": "Enter your raw thoughts, social issues, or daydreams",
        "contemplate_placeholder": "e.g., More people work at cafes nowâ€”does ambient noise boost productivity?\ne.g., People only read news that confirms their viewsâ€”echo chambers?\ne.g., If AI paints, is it art?",
        "contemplate_button": "ðŸ§  Transform to Research Design",
        "contemplate_depth": "Depth Level",
        "depth_spark": "ðŸ”¥ Spark (Quick)",
        "depth_explore": "ðŸ”­ Explore (Variable Expansion)",
        "depth_architect": "ðŸ—ï¸ Architect (Full Framework)",
        "master_title": "ðŸŽ“ Master Dialogue",
        "master_desc": "ðŸ“– Reinterpret your research through a master's epistemology | Perplexity-verified",
        "master_input": "Enter a research question for the master",
        "master_placeholder": "e.g., Do digital platforms deepen labor inequality?\ne.g., How will quantum computing affect cryptography?\ne.g., How should copyright be redefined in the generative AI era?",
        "master_button": "ðŸŽ“ Ask the Master",
        "master_select": "Select Master",
        "master_category": "Field",
        "cat_social": "ðŸ›ï¸ Social Science",
        "cat_engineer": "âš™ï¸ Engineering & Science",
        "cat_art": "ðŸŽ¨ Arts & Humanities",
        "gap_title": "ðŸŒ± Gap-Mining", "gap_desc": "Verify Originality + Find Gaps + Improve RQ",
        "method_title": "âš–ï¸ Methodology Validation", "method_desc": "Anticipate Reviewer Attacks + Defense",
        "draft_title": "ðŸ“ Draft Writing (PRO)", "draft_desc": "Claude AI writes academic drafts",
        "polish_title": "âœï¸ Polishing (PRO)", "polish_desc": "Claude AI polishes to academic style",
        "diagnosis_title": "ðŸ”¬ Final Diagnosis (PRO)", "diagnosis_desc": "3-Engine Hybrid: Perplexity + Gemini + Claude",
        "submit_title": "ðŸ Submission Strategy", "submit_desc": "Journal Recommendations + Abstract",
        "references_title": "ðŸ“š APA References", "references_desc": "Latest Papers via Perplexity + APA 7th",
        "file_upload": "ðŸ“„ Upload File", "analyze_button": "ðŸ” Analyze", "validate_button": "ðŸ§ª Validate",
        "strategy_button": "ðŸ“¤ Generate Strategy", "search_button": "ðŸ“š Find References", "analyzing": "Analyzing...",
        "result": "Result", "download": "ðŸ’¾ Download", "ask_more": "ðŸ’¬ Ask More", "repolish": "ðŸ”„ Re-polish",
        "placeholder_idea": "Enter your research idea...", "placeholder_method": "Enter your methodology...",
        "placeholder_abstract": "Enter your abstract...", "placeholder_topic": "Enter research topic...",
        "error_empty": "âŒ Please enter content.", "error_limit": "âŒ You've used all free analyses!",
        "welcome": "Welcome", "account_info": "Account Info", "weekly_reset": "*Resets every Monday*",
        "security": "ðŸ”’ Security: SHA256 Encryption", "invalid_cred": "âŒ Invalid credentials",
        "pro_only": "ðŸ’Ž PRO feature only!", "draft_topic": "Research Topic & Overview",
        "section_select": "Section to Write", "polish_input": "Text to Polish", "full_paper": "Full Paper",
        "generate_draft": "ðŸ“ Generate Draft", "start_polish": "âœï¸ Start Polishing", "diagnose_button": "ðŸ”¬ Diagnose"
    }
}

def T(key):
    lang = st.session_state.get("language", "ko")
    return LANGUAGES.get(lang, LANGUAGES["ko"]).get(key, key)

if "language" not in st.session_state:
    st.session_state.language = "ko"

# ============================================
# ðŸ”’ API (st.secrets)
# ============================================
try:
    PPLX_API_KEY = st.secrets["api_keys"]["PPLX_API_KEY"]
    GEMINI_API_KEY = st.secrets["api_keys"]["GEMINI_API_KEY"]
    CLAUDE_API_KEY = st.secrets["api_keys"]["CLAUDE_API_KEY"]
except Exception:
    st.error("âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    st.markdown("""
### Streamlit Cloud â†’ Settings â†’ Secrets
```toml
[api_keys]
PPLX_API_KEY = "pplx-..."
GEMINI_API_KEY = "AIzaSy..."
CLAUDE_API_KEY = "sk-ant-api03-..."
```
    """)
    st.stop()

GEMINI_MODEL = "gemini-2.0-flash"
CLAUDE_MODEL = "claude-sonnet-4-5-20250929"

pplx = openai.OpenAI(api_key=PPLX_API_KEY, base_url="https://api.perplexity.ai")
genai.configure(api_key=GEMINI_API_KEY)
gemini = genai.GenerativeModel(GEMINI_MODEL)
claude = anthropic.Anthropic(api_key=CLAUDE_API_KEY)

# ============================================
# ê±°ìž¥ ë°ì´í„°ë² ì´ìŠ¤
# ============================================
MASTERS = {
    "social": {
        "Foucault": {"name_ko": "ë¯¸ì…¸ í‘¸ì½”", "frame": "power-knowledge nexus, discourse analysis, genealogy of institutions",
                     "lens": "Analyze how power structures and institutional discourses shape the phenomenon. Identify whose knowledge is privileged and what is marginalized."},
        "Bourdieu": {"name_ko": "í”¼ì—ë¥´ ë¶€ë¥´ë””ì™¸", "frame": "habitus, cultural capital, field theory, symbolic violence",
                     "lens": "Examine the role of cultural capital, habitus reproduction, and field dynamics. Identify symbolic violence mechanisms."},
        "Weber": {"name_ko": "ë§‰ìŠ¤ ë² ë²„", "frame": "ideal types, rationalization, verstehen, bureaucracy, legitimacy",
                  "lens": "Construct ideal types for comparison. Analyze rationalization processes and legitimacy structures through interpretive understanding."},
        "Habermas": {"name_ko": "ìœ„ë¥´ê² í•˜ë²„ë§ˆìŠ¤", "frame": "communicative action, public sphere, lifeworld vs system",
                     "lens": "Evaluate communicative rationality vs strategic action. Assess public sphere conditions and system colonization of lifeworld."},
        "Giddens": {"name_ko": "ì•¤ì„œë‹ˆ ê¸°ë“ ìŠ¤", "frame": "structuration theory, duality of structure, reflexive modernity",
                    "lens": "Apply the duality of structureâ€”how agents reproduce and transform structures through practice. Examine reflexive modernization."}
    },
    "engineer": {
        "Einstein": {"name_ko": "ì•Œë² ë¥´íŠ¸ ì•„ì¸ìŠˆíƒ€ì¸", "frame": "thought experiments, relativity of reference frames, invariance principles",
                     "lens": "Strip the problem to its invariant core. Design thought experiments that isolate variables. Seek the simplest formulation that preserves all observable constraints."},
        "Feynman": {"name_ko": "ë¦¬ì²˜ë“œ íŒŒì¸ë§Œ", "frame": "first-principles reasoning, path integrals, simplification through analogy",
                    "lens": "Decompose to first principles. If you cannot explain it simply, it is not understood. Map the problem space using multiple representational frames."},
        "Turing": {"name_ko": "ì•¨ëŸ° íŠœë§", "frame": "computability, formal systems, machine intelligence, halting problem",
                   "lens": "Define the problem as a formal system. Identify what is computable vs undecidable. Design the minimal machine that solves the stated task."},
        "Shannon": {"name_ko": "í´ë¡œë“œ ì„€ë„Œ", "frame": "information theory, entropy, channel capacity, signal vs noise",
                    "lens": "Quantify information content and noise. Identify channel constraints. Optimize signal transmission within theoretical bounds."},
        "Curie": {"name_ko": "ë§ˆë¦¬ í€´ë¦¬", "frame": "empirical rigor, measurement precision, systematic experimentation",
                  "lens": "Design experiments with maximum measurement precision. Control for confounds systematically. Let data speak before theory."}
    },
    "art": {
        "Bach": {"name_ko": "ìš”í•œ ì„¸ë°”ìŠ¤ì°¬ ë°”í", "frame": "counterpoint, fugal structure, mathematical harmony, thematic transformation",
                 "lens": "Identify the core theme and develop it through systematic variation. Layer multiple independent voices that create emergent harmony."},
        "DaVinci": {"name_ko": "ë ˆì˜¤ë‚˜ë¥´ë„ ë‹¤ ë¹ˆì¹˜", "frame": "interdisciplinary synthesis, observation-based design, sfumato thinking",
                    "lens": "Cross-pollinate between domains. Begin with meticulous observation. Embrace ambiguity (sfumato) as a generative force rather than a problem."},
        "Wittgenstein": {"name_ko": "ë£¨íŠ¸ë¹„ížˆ ë¹„íŠ¸ê²ìŠˆíƒ€ì¸", "frame": "language games, family resemblance, limits of language, showing vs saying",
                         "lens": "Examine the language game in which the problem exists. Identify what can be said clearly and what can only be shown. Map family resemblances."},
        "Arendt": {"name_ko": "í•œë‚˜ ì•„ë ŒíŠ¸", "frame": "vita activa, banality of evil, public space, natality, plurality",
                   "lens": "Distinguish labor/work/action. Examine how plurality is maintained or destroyed. Assess whether the phenomenon creates or forecloses public space."},
        "Barthes": {"name_ko": "ë¡¤ëž‘ ë°”ë¥´íŠ¸", "frame": "mythology, death of the author, readerly vs writerly texts, punctum/studium",
                    "lens": "Decode the mythology embedded in the phenomenon. Identify what punctum disrupts the studium. Analyze the gap between authorial intent and reader production."}
    }
}

# ============================================
# Protocol-Task-Constraint í”„ë¡¬í”„íŠ¸ ë¹Œë”
# ============================================
def build_prompt(protocol, task, constraint, payload, context=""):
    """ê³ ë°€ë„ ëª…ë ¹ì–´ êµ¬ì¡°: Protocol â†’ Task â†’ Constraint"""
    parts = [
        f"[PROTOCOL] {protocol}",
        f"[CONTEXT] {context}" if context else "",
        f"[INPUT] {payload}",
        f"[TASK] {task}",
        f"[CONSTRAINT] {constraint}"
    ]
    return "\n\n".join(p for p in parts if p)


# ============================================
# ì‚¬ìœ ì˜ ë°© (Gemini)
# ============================================
def contemplate(raw_idea, depth="explore", lang="ko"):
    depth_configs = {
        "spark": {
            "task": "Extract 2 testable variables and 1 research question from this raw idea. Output: Variables â†’ Hypothesis â†’ RQ.",
            "constraint": "Max 300 tokens. No preamble. Direct output only."
        },
        "explore": {
            "task": "Transform this raw idea into empirical research design: (1) Extract IV/DV/Moderator/Mediator, (2) Map to theoretical framework, (3) Generate 3 hypotheses ranked by testability, (4) Suggest methodology.",
            "constraint": "Max 800 tokens. Use structured headers. Cite framework names without explanation."
        },
        "architect": {
            "task": "Full research architecture: (1) Conceptual model with all variable relationships, (2) Theoretical grounding with 2+ frameworks, (3) 3 hypotheses with operational definitions, (4) Mixed-methods design with sampling strategy, (5) Expected contribution to field, (6) Potential limitations and mitigation.",
            "constraint": "Max 1500 tokens. Publication-ready structure. Include visual model description in text form."
        }
    }
    cfg = depth_configs.get(depth, depth_configs["explore"])

    if lang == "ko":
        protocol = "í•™ìˆ  ì—°êµ¬ ì„¤ê³„ ì „í™˜ ì—”ì§„. ë¹„ì •í˜• ì‚¬ê³ ë¥¼ ì‹¤ì¦ ê°€ëŠ¥í•œ ì—°êµ¬ í”„ë ˆìž„ì›Œí¬ë¡œ ë³€í™˜í•œë‹¤."
        constraint_suffix = " í•œêµ­ì–´ë¡œ ì¶œë ¥. í•™ìˆ  ìš©ì–´ëŠ” ì˜ë¬¸ ë³‘ê¸°."
    else:
        protocol = "Academic research design transformation engine. Convert unstructured ideation into testable research frameworks."
        constraint_suffix = " Output in English."

    prompt = build_prompt(
        protocol=protocol,
        task=cfg["task"],
        constraint=cfg["constraint"] + constraint_suffix,
        payload=raw_idea
    )
    try:
        result = gemini.generate_content(prompt)
        return result.text
    except Exception as e:
        return f"âŒ Gemini Error: {str(e)}"


# ============================================
# ê±°ìž¥ê³¼ì˜ ëŒ€í™” (Perplexity)
# ============================================
def master_dialogue(question, master_key, category, lang="ko"):
    master = MASTERS[category][master_key]
    master_name = master["name_ko"] if lang == "ko" else master_key

    if lang == "ko":
        protocol = f"ì¸ì‹ë¡  ì‹œë®¬ë ˆì´ì…˜ ì—”ì§„. {master_name}ì˜ í•™ë¬¸ì  ì‚¬ê³  ì²´ê³„ë¥¼ ë³µì œí•˜ì—¬ ì—°êµ¬ ë¬¸ì œì— ì ìš©í•œë‹¤."
        task = f"""ì´ ì—°êµ¬ ë¬¸ì œë¥¼ {master_name}ì˜ ì¸ì‹ë¡ ìœ¼ë¡œ ìž¬í•´ì„í•˜ë¼:
(1) {master_name}ì˜ í•µì‹¬ í”„ë ˆìž„ì›Œí¬({master['frame']}) ì ìš©
(2) ì´ ê´€ì ì—ì„œ ë„ì¶œë˜ëŠ” ì—°êµ¬ì§ˆë¬¸ ìž¬êµ¬ì„±
(3) ë°©ë²•ë¡ ì  í•¨ì˜
(4) ì´ ê´€ì ì˜ í•œê³„ì™€ ë³´ì™„ì 
(5) ìµœì‹  í•™ìˆ  ë™í–¥ì—ì„œ ì´ í”„ë ˆìž„ì›Œí¬ì˜ í˜„ìž¬ ì ìš© ì‚¬ë¡€"""
        constraint = "ìµœì‹  í•™ìˆ  ë…¼ë¬¸ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì¦ì  ê·¼ê±° í¬í•¨. í•œêµ­ì–´ ì¶œë ¥. í•µì‹¬ ê°œë…ì€ ì›ì–´ ë³‘ê¸°. Max 1200 tokens."
    else:
        protocol = f"Epistemology simulation engine. Replicate {master_key}'s intellectual framework and apply to research problem."
        task = f"""Reinterpret this research problem through {master_key}'s epistemology:
(1) Apply core framework: {master['frame']}
(2) Reconstructed research question from this lens
(3) Methodological implications
(4) Limitations of this perspective and complementary approaches
(5) Current academic applications of this framework with recent citations"""
        constraint = "Include empirical evidence from recent academic literature. English output. Max 1200 tokens."

    lens_instruction = f"[EPISTEMOLOGICAL LENS] {master['lens']}"

    prompt = build_prompt(
        protocol=protocol,
        task=task,
        constraint=constraint,
        payload=question,
        context=lens_instruction
    )
    try:
        response = pplx.chat.completions.create(
            model="sonar-pro",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ Perplexity Error: {str(e)}"


# ============================================
# ê³ ë„í™”ëœ ê¸°ì¡´ ê¸°ëŠ¥ (Protocol-Task-Constraint)
# ============================================
def analyze_with_ai(payload, mode):
    if not payload.strip():
        return T("error_empty")
    lang = st.session_state.language
    try:
        # Phase 1: Perplexity í•™ìˆ  ê²€ìƒ‰
        search_q = f"Recent academic research: {payload[:500]}" if lang == "en" else f"í•™ìˆ  ì—°êµ¬ ìµœì‹  ë™í–¥: {payload[:500]}"
        p_resp = pplx.chat.completions.create(
            model="sonar-pro",
            messages=[{"role": "user", "content": search_q}]
        )
        context = p_resp.choices[0].message.content

        # Phase 2: Gemini ë¶„ì„ (Protocol-Task-Constraint)
        prompts = {
            "gap": {
                "protocol": "Research gap identification engine." if lang == "en" else "ì—°êµ¬ ê³µë°± ì‹ë³„ ì—”ì§„.",
                "task": "Identify: (1) 3 specific research gaps with evidence, (2) Improved research question addressing largest gap, (3) Impact Score 0-100 with justification." if lang == "en" else "ì‹ë³„: (1) ê·¼ê±° ê¸°ë°˜ ì—°êµ¬ ê³µë°± 3ê°œ, (2) ìµœëŒ€ ê³µë°± í•´ì†Œ ì—°êµ¬ì§ˆë¬¸, (3) Impact Score 0-100 ê·¼ê±° í¬í•¨.",
                "constraint": f"Base analysis on: {context[:1000]}. {'English output.' if lang == 'en' else 'í•œêµ­ì–´ ì¶œë ¥.'} Max 800 tokens."
            },
            "method": {
                "protocol": "Methodology stress-test engine." if lang == "en" else "ë°©ë²•ë¡  ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì—”ì§„.",
                "task": "Execute: (1) 3 methodological vulnerabilities ranked by severity, (2) Reviewer attack vectors per vulnerability, (3) Defense strategy per attack, (4) Robustness Score 0-100." if lang == "en" else "ì‹¤í–‰: (1) ì‹¬ê°ë„ìˆœ ë°©ë²•ë¡  ì·¨ì•½ì  3ê°œ, (2) ì·¨ì•½ì ë³„ ì‹¬ì‚¬ìœ„ì› ê³µê²© ë²¡í„°, (3) ê³µê²©ë³„ ë°©ì–´ ì „ëžµ, (4) ê²¬ê³ ì„± ì ìˆ˜ 0-100.",
                "constraint": f"Base analysis on: {context[:1000]}. {'English output.' if lang == 'en' else 'í•œêµ­ì–´ ì¶œë ¥.'} Max 800 tokens."
            },
            "submit": {
                "protocol": "Journal-fit optimization engine." if lang == "en" else "ì €ë„ ì í•©ì„± ìµœì í™” ì—”ì§„.",
                "task": "Deliver: (1) 3 target journals with fit-score, scope match rationale, recent similar publications, (2) Abstract rewrite optimized for top journal, (3) Submission timing recommendation." if lang == "en" else "ì œê³µ: (1) ì í•©ë„ ì ìˆ˜ í¬í•¨ íƒ€ê²Ÿ ì €ë„ 3ê³³ + ìœ ì‚¬ ê²Œìž¬ë…¼ë¬¸, (2) 1ìˆœìœ„ ì €ë„ ìµœì í™” Abstract ìž¬ìž‘ì„±, (3) íˆ¬ê³  íƒ€ì´ë° ê¶Œê³ .",
                "constraint": f"Base analysis on: {context[:1000]}. {'English output.' if lang == 'en' else 'í•œêµ­ì–´ ì¶œë ¥.'} Max 800 tokens."
            },
            "references": {
                "protocol": "APA 7th citation generator with verification." if lang == "en" else "APA 7íŒ ì°¸ê³ ë¬¸í—Œ ìƒì„± ì—”ì§„.",
                "task": "Generate 5-10 references: (1) APA 7th format strictly, (2) Relevance score per reference, (3) Categorize as foundational/methodological/recent." if lang == "en" else "5-10ê°œ ì°¸ê³ ë¬¸í—Œ ìƒì„±: (1) APA 7íŒ ì—„ê²© ì¤€ìˆ˜, (2) ê´€ë ¨ì„± ì ìˆ˜, (3) ê¸°ì´ˆ/ë°©ë²•ë¡ /ìµœì‹ ìœ¼ë¡œ ë¶„ë¥˜.",
                "constraint": f"Base analysis on: {context[:1000]}. {'English output.' if lang == 'en' else 'í•œêµ­ì–´ ì¶œë ¥.'} Max 1000 tokens."
            }
        }
        cfg = prompts.get(mode, prompts["gap"])
        prompt = build_prompt(
            protocol=cfg["protocol"],
            task=cfg["task"],
            constraint=cfg["constraint"],
            payload=payload
        )
        result = gemini.generate_content(prompt)
        return result.text
    except Exception as e:
        return f"âŒ Error: {str(e)}"


def draft_with_claude(topic, section_type, lang="ko"):
    section_tasks = {
        "intro": "Write Introduction: (1) Research context with field positioning, (2) Gap identification from literature, (3) Purpose statement, (4) Significance, (5) RQ/Hypotheses.",
        "method": "Write Methods: (1) Research design with justification, (2) Participants/sampling with power analysis rationale, (3) Instruments with validity evidence, (4) Procedure, (5) Analysis plan.",
        "discussion": "Write Discussion: (1) Key findings interpretation, (2) Theoretical implications with framework integration, (3) Practical implications, (4) Limitations with mitigation, (5) Future research agenda."
    }
    task = section_tasks.get(section_type, section_tasks["intro"])
    lang_c = "í•œêµ­ì–´ ì¶œë ¥. í•™ìˆ  ìš©ì–´ ì˜ë¬¸ ë³‘ê¸°." if lang == "ko" else "English output."

    prompt = build_prompt(
        protocol="Academic manuscript drafting engine. Publication-ready quality.",
        task=task,
        constraint=f"500-800 words. Formal academic register. {lang_c}",
        payload=topic
    )
    try:
        msg = claude.messages.create(
            model=CLAUDE_MODEL, max_tokens=2000, temperature=0.7,
            messages=[{"role": "user", "content": prompt}]
        )
        return msg.content[0].text
    except Exception as e:
        return f"âŒ Claude Error: {str(e)}"


def polish_with_claude(text, lang="ko"):
    lang_c = "í•œêµ­ì–´ ì¶œë ¥." if lang == "ko" else "English output."
    prompt = build_prompt(
        protocol="Academic prose refinement engine.",
        task="Refine: (1) Elevate register to publication standard, (2) Tighten syntax and eliminate redundancy, (3) Insert precise terminology, (4) Output Before/After comparison, (5) Score: Academic Rigor / Clarity / Conciseness each 0-100.",
        constraint=f"Preserve original argument structure. {lang_c} Max 1200 tokens.",
        payload=text
    )
    try:
        msg = claude.messages.create(
            model=CLAUDE_MODEL, max_tokens=2500, temperature=0.3,
            messages=[{"role": "user", "content": prompt}]
        )
        return msg.content[0].text
    except Exception as e:
        return f"âŒ Claude Error: {str(e)}"


def hybrid_diagnosis(paper_text, lang="ko"):
    lang_c = "í•œêµ­ì–´ ì¶œë ¥." if lang == "ko" else "English output."
    try:
        # Phase 1: Perplexity
        p1_prompt = build_prompt(
            protocol="Academic literature positioning engine.",
            task="Analyze: (1) Current field trajectory 2023-2026, (2) Key competing/complementary works, (3) Reference adequacy assessment, (4) Gap this paper addresses, (5) Positioning within field.",
            constraint=f"Max 500 tokens. {lang_c}",
            payload=paper_text[:1500]
        )
        p1 = pplx.chat.completions.create(model="sonar-pro", messages=[{"role": "user", "content": p1_prompt}])
        perplexity_out = p1.choices[0].message.content

        # Phase 2: Gemini
        p2_prompt = build_prompt(
            protocol="Research value assessment engine.",
            task="Evaluate: (1) Originality X/100 with evidence, (2) Theoretical + Practical contribution, (3) Impact prediction (citation potential, field influence), (4) Gap fulfillment X/100.",
            constraint=f"Max 600 tokens. {lang_c}",
            payload=paper_text[:2000],
            context=f"[LITERATURE ANALYSIS] {perplexity_out}"
        )
        gemini_out = gemini.generate_content(p2_prompt).text

        # Phase 3: Claude
        p3_prompt = build_prompt(
            protocol="Manuscript quality audit engine.",
            task="Audit: (1) Logic & Flow X/100 with specific weak points, (2) Writing Quality X/100, (3) Structure completeness per IMRAD section, (4) Top 3 revision priorities with concrete action items.",
            constraint=f"Max 800 tokens. {lang_c}",
            payload=paper_text[:3000],
            context=f"[LITERATURE] {perplexity_out[:500]}\n[VALUE] {gemini_out[:500]}"
        )
        c_msg = claude.messages.create(
            model=CLAUDE_MODEL, max_tokens=2500, temperature=0.3,
            messages=[{"role": "user", "content": p3_prompt}]
        )
        claude_out = c_msg.content[0].text

        divider = "\n\n---\n\n"
        if lang == "ko":
            return f"# ðŸ”¬ ìµœì¢… ë…¼ë¬¸ ì§„ë‹¨ ë³´ê³ ì„œ{divider}## ðŸ“Š Phase 1: í•™ìˆ  DB ë¶„ì„ (Perplexity)\n\n{perplexity_out}{divider}## ðŸ’Ž Phase 2: ê°€ì¹˜ í‰ê°€ (Gemini)\n\n{gemini_out}{divider}## ðŸ¤– Phase 3: ì›ê³  í’ˆì§ˆ ê°ì‚¬ (Claude)\n\n{claude_out}{divider}*Powered by Perplexity + Gemini + Claude*"
        else:
            return f"# ðŸ”¬ Final Diagnosis Report{divider}## ðŸ“Š Phase 1: Literature Analysis (Perplexity)\n\n{perplexity_out}{divider}## ðŸ’Ž Phase 2: Value Assessment (Gemini)\n\n{gemini_out}{divider}## ðŸ¤– Phase 3: Manuscript Audit (Claude)\n\n{claude_out}{divider}*Powered by Perplexity + Gemini + Claude*"
    except Exception as e:
        return f"âŒ Hybrid Diagnosis Error: {str(e)}"


# ============================================
# ì‚¬ìš©ìž ì‹œìŠ¤í…œ
# ============================================
USER_DB_FILE = "users_db.json"

def hash_pw(pw): return hashlib.sha256(pw.encode()).hexdigest()
def verify_pw(inp, stored): return hash_pw(inp) == stored
def load_users():
    try:
        with open(USER_DB_FILE, 'r', encoding='utf-8') as f: return json.load(f)
    except: return {}
def save_users(users):
    with open(USER_DB_FILE, 'w', encoding='utf-8') as f: json.dump(users, f, indent=2, ensure_ascii=False)
    try: os.chmod(USER_DB_FILE, 0o600)
    except: pass

def init_accounts():
    users = load_users()
    ch = False
    for uname, tier in [("test_free", "free"), ("test_pro", "pro")]:
        if uname not in users:
            users[uname] = {"password": hash_pw("Test1234!"), "email": f"{tier}@test.com", "tier": tier,
                            "usage_count": 0, "week_start": datetime.now().isoformat(), "created_at": datetime.now().isoformat()}
            ch = True
    if ch: save_users(users)
init_accounts()

def check_reset(ud):
    try: return datetime.now() - datetime.fromisoformat(ud.get("week_start", datetime.now().isoformat())) > timedelta(days=7)
    except: return True

def update_usage(un):
    users = load_users()
    if un in users:
        if check_reset(users[un]):
            users[un]["usage_count"] = 0
            users[un]["week_start"] = datetime.now().isoformat()
        users[un]["usage_count"] += 1
        save_users(users)

def remaining_uses(un):
    users = load_users()
    if un in users:
        if check_reset(users[un]): return 10
        return max(0, 10 - users[un].get("usage_count", 0))
    return 0

def check_limit():
    if st.session_state.user_tier == "pro": return True
    r = remaining_uses(st.session_state.username)
    if r <= 0:
        st.error(T("error_limit"))
        st.warning(f"ðŸ’Ž {T('upgrade')}")
        return False
    return True

def extract_text(file):
    if not file: return ""
    try:
        if file.name.endswith('.pdf'):
            return "".join(p.extract_text() or "" for p in PyPDF2.PdfReader(file).pages)[:3000]
        if file.name.endswith('.docx'):
            return "\n".join(p.text.strip() for p in docx.Document(file).paragraphs)[:3000]
        return file.read().decode('utf-8', errors='ignore')[:3000]
    except Exception as e: return f"Error: {e}"

# ============================================
# ì„¸ì…˜ ì´ˆê¸°í™”
# ============================================
for k, v in [("logged_in", False), ("username", None), ("user_tier", "free"),
             ("sessions", {"contemplate": {}, "master": {}, "gap": {}, "method": {}, "draft": {}, "polish": {}, "diagnosis": {}, "submit": {}, "references": {}})]:
    if k not in st.session_state:
        st.session_state[k] = v

# ============================================
# ì–¸ì–´ ì„ íƒ
# ============================================
_, col_lang = st.columns([5, 1])
with col_lang:
    cur = st.session_state.get("language", "ko")
    sel = st.selectbox("ðŸŒ", list(LANGUAGES.keys()), format_func=lambda x: f"{LANGUAGES[x]['flag']} {LANGUAGES[x]['name']}",
                       index=list(LANGUAGES.keys()).index(cur), label_visibility="collapsed")
    if sel != cur:
        st.session_state.language = sel
        st.rerun()
st.markdown("---")

# ============================================
# ë¡œê·¸ì¸
# ============================================
if not st.session_state.logged_in:
    st.markdown(f"<h1 style='text-align:center'>{T('app_title')}</h1>", unsafe_allow_html=True)
    st.markdown(f"<p style='text-align:center;color:#888'>{T('app_subtitle')}</p>", unsafe_allow_html=True)
    st.markdown("---")
    _, cc, _ = st.columns([1, 2, 1])
    with cc:
        t1, t2 = st.tabs([T("login"), T("signup")])
        with t1:
            st.markdown(f"### {T('login')}")
            with st.expander(T("test_account")):
                st.info("**FREE**: test_free / Test1234!\n**PRO**: test_pro / Test1234!")
            lu = st.text_input(T("username"), key="lu")
            lp = st.text_input(T("password"), type="password", key="lp")
            if st.button(T("login_button"), type="primary", use_container_width=True):
                users = load_users()
                if lu in users and verify_pw(lp, users[lu]["password"]):
                    st.session_state.logged_in = True
                    st.session_state.username = lu
                    st.session_state.user_tier = users[lu].get("tier", "free")
                    st.success(f"âœ… {T('welcome')}, {lu}!")
                    st.balloons(); st.rerun()
                else: st.error(T("invalid_cred"))
        with t2:
            st.markdown(f"### {T('signup')}")
            su = st.text_input(T("username"), key="su")
            se = st.text_input(T("email"), key="se")
            sp = st.text_input(T("password"), type="password", key="sp")
            spc = st.text_input(T("password_confirm"), type="password", key="spc")
            if st.button(T("signup_button"), type="primary", use_container_width=True):
                users = load_users()
                if len(su) < 4: st.error("âŒ 4ìž ì´ìƒ")
                elif su in users: st.error("âŒ ì´ë¯¸ ì¡´ìž¬")
                elif sp != spc: st.error("âŒ ë¹„ë°€ë²ˆí˜¸ ë¶ˆì¼ì¹˜")
                elif len(sp) < 6: st.error("âŒ 6ìž ì´ìƒ")
                else:
                    users[su] = {"password": hash_pw(sp), "email": se, "tier": "free", "usage_count": 0,
                                 "week_start": datetime.now().isoformat(), "created_at": datetime.now().isoformat()}
                    save_users(users); st.success("âœ… ê°€ìž… ì™„ë£Œ! ë¡œê·¸ì¸í•˜ì„¸ìš”.")
        st.markdown("---"); st.caption(T("security"))
    st.stop()

# ============================================
# ì‚¬ì´ë“œë°”
# ============================================
with st.sidebar:
    st.markdown(f"## {T('app_title')}")
    st.success(f"ðŸ‘¤ **{st.session_state.username}**")
    if st.session_state.user_tier == "free":
        r = remaining_uses(st.session_state.username)
        st.warning(T("free_plan")); st.progress(r / 10)
        st.caption(f"{T('remaining')}: **{r}/10**"); st.caption(T("weekly_reset"))
        if st.button(T("upgrade"), use_container_width=True): st.info("ðŸ’Ž PRO coming soon!")
    else:
        st.success(T("pro_plan")); st.caption(f"âœ… {T('unlimited')}")
    st.divider()
    if st.button(T("logout"), use_container_width=True):
        st.session_state.logged_in = False; st.session_state.username = None; st.session_state.user_tier = "free"; st.rerun()
    st.divider(); st.caption(T("security")); st.divider()
    st.caption("ðŸ”§ Engine Status")
    st.caption("âœ… Perplexity: sonar-pro")
    st.caption(f"âœ… Gemini: {GEMINI_MODEL}")
    st.caption(f"âœ… Claude: {CLAUDE_MODEL}")

# ============================================
# ë©”ì¸ ì•±
# ============================================
st.title(T("app_title"))
st.markdown(T("app_subtitle"))
st.markdown("---")

tabs = st.tabs([
    T("contemplate_tab"), T("master_tab"),
    T("gap_tab"), T("method_tab"), T("draft_tab"), T("polish_tab"),
    T("diagnosis_tab"), T("submit_tab"), T("references_tab"), T("storage_tab")
])

# â”€â”€ ðŸ§  ì‚¬ìœ ì˜ ë°© â”€â”€
with tabs[0]:
    st.header(T("contemplate_title"))
    st.info(T("contemplate_desc"))
    raw_idea = st.text_area(T("contemplate_input"), height=180, placeholder=T("contemplate_placeholder"), key="contemplate_text")
    c1, c2 = st.columns(2)
    with c1:
        depth = st.selectbox(T("contemplate_depth"),
            ["spark", "explore", "architect"],
            format_func=lambda x: {"spark": T("depth_spark"), "explore": T("depth_explore"), "architect": T("depth_architect")}[x])
    with c2:
        con_lang = st.selectbox("Language", ["ko", "en"], format_func=lambda x: "í•œêµ­ì–´" if x == "ko" else "English", key="con_lang")
    if st.button(T("contemplate_button"), type="primary", use_container_width=True):
        if not check_limit(): st.stop()
        if raw_idea.strip():
            with st.spinner(T("analyzing")):
                result = contemplate(raw_idea, depth, con_lang)
                st.session_state.sessions["contemplate"] = {"result": result}
                update_usage(st.session_state.username); st.rerun()
        else: st.error(T("error_empty"))
    data = st.session_state.sessions.get("contemplate")
    if data:
        st.markdown(f"### ðŸ“Š {T('result')}")
        st.markdown(data['result'])
        st.download_button(T("download"), data['result'], "contemplation.txt")

# â”€â”€ ðŸŽ“ ê±°ìž¥ê³¼ì˜ ëŒ€í™” â”€â”€
with tabs[1]:
    st.header(T("master_title"))
    st.info(T("master_desc"))
    cat = st.selectbox(T("master_category"), ["social", "engineer", "art"],
        format_func=lambda x: {"social": T("cat_social"), "engineer": T("cat_engineer"), "art": T("cat_art")}[x])
    lang_now = st.session_state.language
    master_options = list(MASTERS[cat].keys())
    master_labels = [f"{MASTERS[cat][m]['name_ko']} ({m})" if lang_now == "ko" else m for m in master_options]
    master_key = st.selectbox(T("master_select"), master_options, format_func=lambda x: f"{MASTERS[cat][x]['name_ko']} ({x})" if lang_now == "ko" else x)
    question = st.text_area(T("master_input"), height=150, placeholder=T("master_placeholder"), key="master_text")
    m_lang = st.selectbox("Language", ["ko", "en"], format_func=lambda x: "í•œêµ­ì–´" if x == "ko" else "English", key="m_lang")
    if st.button(T("master_button"), type="primary", use_container_width=True):
        if not check_limit(): st.stop()
        if question.strip():
            master_display = MASTERS[cat][master_key]['name_ko'] if m_lang == "ko" else master_key
            with st.spinner(f"ðŸŽ“ {master_display} ì‚¬ìœ  ì¤‘..." if m_lang == "ko" else f"ðŸŽ“ {master_display} is thinking..."):
                result = master_dialogue(question, master_key, cat, m_lang)
                st.session_state.sessions["master"] = {"result": result, "master": master_display}
                update_usage(st.session_state.username); st.rerun()
        else: st.error(T("error_empty"))
    data = st.session_state.sessions.get("master")
    if data:
        st.markdown(f"### ðŸŽ“ {data.get('master', '')}ì˜ ë‹µë³€")
        st.markdown(data['result'])
        st.download_button(T("download"), data['result'], "master_dialogue.txt")

# â”€â”€ ðŸŒ± Gap-Mining â”€â”€
with tabs[2]:
    st.header(T("gap_title")); st.info(T("gap_desc"))
    c1, c2 = st.columns([1, 3])
    fg = c1.file_uploader(T("file_upload"), type=['pdf','docx','txt'], key="f1")
    tg = c2.text_area("ðŸ’¡", height=150, placeholder=T("placeholder_idea"), key="t1")
    if st.button(T("analyze_button"), type="primary", use_container_width=True):
        if not check_limit(): st.stop()
        payload = extract_text(fg) or tg
        if payload.strip():
            with st.spinner(T("analyzing")):
                r = analyze_with_ai(payload, "gap")
                st.session_state.sessions["gap"] = {"result": r}; update_usage(st.session_state.username); st.rerun()
        else: st.error(T("error_empty"))
    d = st.session_state.sessions.get("gap")
    if d:
        st.markdown(f"### ðŸ“Š {T('result')}"); st.markdown(d['result'])
        st.download_button(T("download"), d['result'], "gap_analysis.txt")
        fq = st.chat_input(T("ask_more"))
        if fq:
            with st.chat_message("user"): st.write(fq)
            with st.spinner("..."):
                a = gemini.generate_content(f"{d['result']}\n\n{fq}").text
            with st.chat_message("assistant"): st.markdown(a)

# â”€â”€ âš–ï¸ ë°©ë²•ë¡  â”€â”€
with tabs[3]:
    st.header(T("method_title")); st.info(T("method_desc"))
    c1, c2 = st.columns([1, 3])
    fm = c1.file_uploader(T("file_upload"), type=['pdf','docx','txt'], key="f2")
    tm = c2.text_area("ðŸ“Š", height=150, placeholder=T("placeholder_method"), key="t2")
    if st.button(T("validate_button"), type="primary", use_container_width=True):
        if not check_limit(): st.stop()
        payload = extract_text(fm) or tm
        if payload.strip():
            with st.spinner(T("analyzing")):
                r = analyze_with_ai(payload, "method")
                st.session_state.sessions["method"] = {"result": r}; update_usage(st.session_state.username); st.rerun()
        else: st.error(T("error_empty"))
    d = st.session_state.sessions.get("method")
    if d:
        st.markdown(f"### ðŸ“Š {T('result')}"); st.markdown(d['result'])
        st.download_button(T("download"), d['result'], "method_validation.txt")

# â”€â”€ ðŸ“ ë“œëž˜í”„íŠ¸ â”€â”€
with tabs[4]:
    st.header(T("draft_title"))
    if st.session_state.user_tier != "pro":
        st.warning(T("pro_only"))
        if st.button(T("upgrade"), use_container_width=True, key="du"): st.info("ðŸ’Ž PRO coming soon!")
        st.stop()
    st.info(T("draft_desc"))
    dt = st.text_area(T("draft_topic"), height=150, placeholder=T("placeholder_idea"), key="di")
    c1, c2 = st.columns(2)
    with c1: sec = st.selectbox(T("section_select"), ["intro", "method", "discussion"],
                format_func=lambda x: {"intro": "Introduction", "method": "Methods", "discussion": "Discussion"}[x])
    with c2: dl = st.selectbox("Language", ["ko", "en"], format_func=lambda x: "í•œêµ­ì–´" if x == "ko" else "English", key="dl")
    if st.button(T("generate_draft"), type="primary", use_container_width=True):
        if not check_limit(): st.stop()
        if dt.strip():
            with st.spinner(T("analyzing")):
                r = draft_with_claude(dt, sec, dl)
                st.session_state.sessions["draft"] = {"result": r}; update_usage(st.session_state.username); st.rerun()
        else: st.error(T("error_empty"))
    d = st.session_state.sessions.get("draft")
    if d:
        st.markdown(f"### ðŸ“„ {T('result')}"); st.markdown(d['result'])
        st.download_button(T("download"), d['result'], "draft.txt")

# â”€â”€ âœï¸ ìœ¤ë¬¸ â”€â”€
with tabs[5]:
    st.header(T("polish_title"))
    if st.session_state.user_tier != "pro":
        st.warning(T("pro_only"))
        if st.button(T("upgrade"), use_container_width=True, key="pu"): st.info("ðŸ’Ž PRO coming soon!")
        st.stop()
    st.info(T("polish_desc"))
    pt = st.text_area(T("polish_input"), height=200, placeholder="í•™ìˆ ì ìœ¼ë¡œ ë‹¤ë“¬ì„ í…ìŠ¤íŠ¸...", key="pi")
    pl = st.selectbox("Language", ["ko", "en"], format_func=lambda x: "í•œêµ­ì–´ ìœ¤ë¬¸" if x == "ko" else "English Polishing", key="pl")
    if st.button(T("start_polish"), type="primary", use_container_width=True):
        if not check_limit(): st.stop()
        if pt.strip():
            with st.spinner(T("analyzing")):
                r = polish_with_claude(pt, pl)
                st.session_state.sessions["polish"] = {"result": r}; update_usage(st.session_state.username); st.rerun()
        else: st.error(T("error_empty"))
    d = st.session_state.sessions.get("polish")
    if d:
        st.markdown(f"### âœ¨ {T('result')}"); st.markdown(d['result'])
        c1, c2 = st.columns(2)
        with c1: st.download_button(T("download"), d['result'], "polished.txt")
        with c2:
            if st.button(T("repolish")): st.session_state.sessions["polish"] = {}; st.rerun()

# â”€â”€ ðŸ”¬ ìµœì¢… ì§„ë‹¨ â”€â”€
with tabs[6]:
    st.header(T("diagnosis_title"))
    if st.session_state.user_tier != "pro":
        st.warning(T("pro_only"))
        if st.button(T("upgrade"), use_container_width=True, key="dgu"): st.info("ðŸ’Ž PRO coming soon!")
        st.stop()
    st.info(T("diagnosis_desc"))
    c1, c2 = st.columns([1, 3])
    fd = c1.file_uploader(T("file_upload"), type=['pdf','docx','txt'], key="df")
    td = c2.text_area(T("full_paper"), height=250, placeholder="ì™„ì„±ëœ ë…¼ë¬¸...", key="dti")
    ddl = st.selectbox("Language", ["ko", "en"], format_func=lambda x: "í•œêµ­ì–´" if x == "ko" else "English", key="ddl")
    if st.button("ðŸ”¬ 3-Engine í•˜ì´ë¸Œë¦¬ë“œ ì§„ë‹¨", type="primary", use_container_width=True):
        if not check_limit(): st.stop()
        payload = extract_text(fd) or td
        if payload.strip():
            pb = st.progress(0); s = st.empty()
            s.info("ðŸ” Phase 1/3: Perplexity..."); pb.progress(10)
            with st.spinner("3-Engine ë¶„ì„ ì¤‘..."):
                r = hybrid_diagnosis(payload, ddl)
                s.success("âœ… ì™„ë£Œ!"); pb.progress(100)
                st.session_state.sessions["diagnosis"] = {"result": r}; update_usage(st.session_state.username); st.rerun()
        else: st.error(T("error_empty"))
    d = st.session_state.sessions.get("diagnosis")
    if d:
        st.markdown("### ðŸ“‹ ì§„ë‹¨ ê²°ê³¼"); st.markdown(d['result'])
        c1, c2, c3 = st.columns(3)
        with c1: st.download_button("ðŸ’¾ ë¦¬í¬íŠ¸", d['result'], "diagnosis.txt")
        with c2: st.download_button("ðŸ“§ ì´ë©”ì¼ìš©", d['result'], "diagnosis_email.txt")
        with c3:
            if st.button("ðŸ”„ ìž¬ì§„ë‹¨"): st.session_state.sessions["diagnosis"] = {}; st.rerun()

# â”€â”€ ðŸ íˆ¬ê³  â”€â”€
with tabs[7]:
    st.header(T("submit_title")); st.info(T("submit_desc"))
    c1, c2 = st.columns([1, 3])
    fs = c1.file_uploader(T("file_upload"), type=['pdf','docx','txt'], key="f3")
    ts = c2.text_area("âœï¸", height=150, placeholder=T("placeholder_abstract"), key="t3")
    if st.button(T("strategy_button"), type="primary", use_container_width=True):
        if not check_limit(): st.stop()
        payload = extract_text(fs) or ts
        if payload.strip():
            with st.spinner(T("analyzing")):
                r = analyze_with_ai(payload, "submit")
                st.session_state.sessions["submit"] = {"result": r}; update_usage(st.session_state.username); st.rerun()
        else: st.error(T("error_empty"))
    d = st.session_state.sessions.get("submit")
    if d:
        st.markdown(f"### ðŸ“Š {T('result')}"); st.markdown(d['result'])
        st.download_button(T("download"), d['result'], "submission_strategy.txt")

# â”€â”€ ðŸ“š ì°¸ê³ ë¬¸í—Œ â”€â”€
with tabs[8]:
    st.header(T("references_title")); st.info(T("references_desc"))
    rt = st.text_input("ðŸ”", placeholder=T("placeholder_topic"))
    if st.button(T("search_button"), type="primary", use_container_width=True):
        if not check_limit(): st.stop()
        if rt.strip():
            with st.spinner(T("analyzing")):
                r = analyze_with_ai(rt, "references")
                st.session_state.sessions["references"] = {"result": r}; update_usage(st.session_state.username); st.rerun()
        else: st.error(T("error_empty"))
    d = st.session_state.sessions.get("references")
    if d:
        st.markdown(f"### ðŸ“š {T('result')}"); st.markdown(d['result'])
        st.download_button(T("download"), d['result'], "references.txt")

# â”€â”€ ðŸ’¾ ì €ìž¥ì†Œ â”€â”€
with tabs[9]:
    st.header(f"ðŸ’¾ {T('storage_tab')}")
    has = False
    for name in ["contemplate", "master", "gap", "method", "draft", "polish", "diagnosis", "submit", "references"]:
        d = st.session_state.sessions.get(name)
        if d and d.get("result"):
            has = True
            with st.expander(f"ðŸ“‚ {name.upper()}"):
                st.text_area(T("result"), d["result"][:500] + "..." if len(d["result"]) > 500 else d["result"],
                             height=150, disabled=True, key=f"s_{name}")
    if not has: st.info("No saved sessions yet.")
    else:
        bj = json.dumps(st.session_state.sessions, ensure_ascii=False, indent=2)
        st.download_button(f"ðŸ’¾ {T('download')} All (JSON)", bj, "strategist_backup.json", use_container_width=True)

st.markdown("---")
st.caption(f"*{T('app_title')} | 2026 | Powered by Perplexity + Gemini + Claude*")
st.caption(f"âœ… sonar-pro + {GEMINI_MODEL} + {CLAUDE_MODEL}")
